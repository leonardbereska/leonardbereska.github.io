<!doctype html>
<html>
  <head>
    {% include head.liquid %}
    {% if site.enable_medium_zoom %}
      <!-- Medium Zoom JS -->
      <script
        defer
        src="{{ site.third_party_libraries.medium_zoom.url.js }}"
        integrity="{{ site.third_party_libraries.medium_zoom.integrity.js }}"
        crossorigin="anonymous"
      ></script>
      <script defer src="{{ '/assets/js/zoom.js' | relative_url | bust_file_cache }}"></script>
    {% endif %}
    {% include scripts/jquery.liquid %}
    {% include scripts/mathjax.liquid %}
    <!-- Distill js -->
    <script src="{{ '/assets/js/distillpub/template.v2.js' | relative_url }}"></script>
    <script src="{{ '/assets/js/distillpub/transforms.v2.js' | relative_url }}"></script>
    <script src="{{ '/assets/js/distillpub/overrides.js' | relative_url }}"></script>
    {% if page._styles %}
      <!-- Page/Post style -->
      <style type="text/css">
        {{ page._styles }}
      </style>
    {% endif %}
    <script src="https://unpkg.com/@popperjs/core@2"></script>
    <script src="https://unpkg.com/tippy.js@6"></script>
    <script src="{{ '/assets/js/distillpub/glossary-tooltips.js' | relative_url }}"></script>
    <link rel="stylesheet" href="https://unpkg.com/tippy.js@6/themes/light.css"/>

      <!-- Dublin Core metadata -->
    <meta name="dc.title" content="Mechanistic Interpretability for AI Safety — A Review">
    <meta name="dc.creator" content="Bereska, Leonard">
    <meta name="dc.creator" content="Gavves, Efstratios">
    <meta name="dc.date" content="2024-04">
    <meta name="dc.type" content="article">
    <meta name="dc.identifier" content="http://arxiv.org/abs/2404.14082">
    <meta name="dc.description" content="Understanding AI systems' inner workings is critical for ensuring value alignment and safety. This review explores mechanistic interpretability: reverse-engineering the computational mechanisms and representations learned by neural networks into human-understandable algorithms and concepts to provide a granular, causal understanding. We establish foundational concepts such as features encoding knowledge within neural activations and hypotheses about their representation and computation. We survey methodologies for causally dissecting model behaviors and assess the relevance of mechanistic interpretability to AI safety. We investigate challenges surrounding scalability, automation, and comprehensive interpretation. We advocate for clarifying concepts, setting standards, and scaling techniques to handle complex models and behaviors and expand to domains such as vision and reinforcement learning. Mechanistic interpretability could help prevent catastrophic outcomes as AI systems become more powerful and inscrutable.">

    <!-- Highwire Press tags -->
    <meta name="citation_title" content="Mechanistic Interpretability for AI Safety — A Review">
    <meta name="citation_author" content="Bereska, Leonard">
    <meta name="citation_author" content="Gavves, Efstratios">
    <meta name="citation_publication_date" content="2024/04">
    <meta name="citation_journal_title" content="CoRR">
    <meta name="citation_arxiv_id" content="2404.14082">
    <meta name="citation_abstract_html_url" content="http://arxiv.org/abs/2404.14082">
    <meta name="citation_fulltext_html_url" content="http://arxiv.org/abs/2404.14082">
    <meta name="citation_pdf_url" content="http://arxiv.org/pdf/2404.14082.pdf">
  </head>

  <d-front-matter>
    <script async type="text/json">
      {
            "title": "{{ page.title }}",
            "description": "{{ page.description }}",
            "published": "{{ page.date | date: '%B %d, %Y' }}",
            "authors": [
              {% for author in page.authors %}
              {
                "author": "{{ author.name }}",
                "authorURL": "{{ author.url }}",
                "affiliations": [
                  {
                    "name": "{{ author.affiliations.name }}",
                    "url": "{{ author.affiliations.url }}"
                  }
                ]
              }{% if forloop.last == false %},{% endif %}
              {% endfor %}
            ],
            "katex": {
              "delimiters": [
                {
                  "left": "$",
                  "right": "$",
                  "display": false
                },
                {
                  "left": "$$",
                  "right": "$$",
                  "display": true
                }
              ]
            }
          }
    </script>
  </d-front-matter>

  <body class="{% if site.navbar_fixed %}fixed-top-nav{% endif %} {% unless site.footer_fixed %}sticky-bottom-footer{% endunless %}">
    <!-- Header -->
    {% include header.liquid %}

    <!-- Content -->
    <div class="post distill">
      <d-title>
        <h1>{{ page.title }}</h1>
        <p>{{ page.description }}</p>
      </d-title>
      {% if page.authors %}
        <d-byline></d-byline>
      {% endif %}

      <d-article>
        {% if page.toc %}
          <d-contents>
            <nav class="l-text figcaption">
              <h3>Contents</h3>
              {% for section in page.toc %}
                <div>
                  <a href="#{{ section.name | slugify }}">{{ section.name }}</a>
                </div>
                {% if section.subsections %}
                  <ul>
                    {% for subsection in section.subsections %}
                      <li>
                        <a href="#{{ subsection.name | slugify }}">{{ subsection.name }}</a>
                        {% if subsection.subsubsections %}
                          <ul>
                            {% for subsubsection in subsection.subsubsections %}
                              <li>
                                <a href="#{{ subsubsection.name | slugify }}">{{ subsubsection.name }}</a>
                              </li>
                            {% endfor %}
                          </ul>
                        {% endif %}
                      </li>
                    {% endfor %}
                  </ul>
                {% endif %}
              {% endfor %}
            </nav>
          </d-contents>
        {% endif %}
        {{ content }}
      </d-article>

      <d-appendix>
        <h3>Citation Information</h3>
        <p>Please cite as:</p>
        <pre class=citation> Bereska, L. & Gavves, E. Mechanistic Interpretability for AI Safety — A Review. CoRR (2024). http://arxiv.org/abs/2404.14082.</pre>
        <p> BibTeX Citation:</p>
        <div class="language-bibtex">
    <div class="highlight">
      <div class="code-display-wrapper">
        <pre class="highlight"><code><span class="nc">@article</span><span class="p">{</span><span class="nl">bereska2024mechanistic</span><span class="p">,</span>
  <span class="na">title</span>   <span class="p">=</span> <span class="s">{Mechanistic Interpretability for AI Safety - A Review}</span><span class="p">,</span>
  <span class="na">author</span>  <span class="p">=</span> <span class="s">{Bereska, Leonard and Gavves, Efstratios}</span><span class="p">,</span>
  <span class="na">year</span>    <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">month</span>   <span class="p">=</span> <span class="s">{Apr}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{CoRR}</span><span class="p">,</span>
  <span class="na">volume</span>  <span class="p">=</span> <span class="s">{abs/2404.14082}</span><span class="p">,</span>
  <span class="na">url</span>     <span class="p">=</span> <span class="s">{http://arxiv.org/abs/2404.14082}</span>
<span class="p">}</span>
</code></pre>
        <button class="copy" type="button" aria-label="Copy code to clipboard">
          <i class="fa-solid fa-clipboard"></i>
        </button>
      </div>
    </div>
  </div>
        <h3>Acknowledgements</h3>
        <p>I am grateful for the invaluable feedback and comments from Leon Lang, Tim Bakker, Jannik Brinkmann, Can Rager, Louis van Harten, Jacqueline Bereska, Thijmen Nijdam, Alice Rigg, Arthur Conmy, and Tom Lieberum. Their insights substantially improved this work.</p>
        <h3>Glossary</h3>
        <dl id="full-glossary"></dl>
        <d-footnote-list></d-footnote-list>
        <d-citation-list></d-citation-list>
      </d-appendix>

      <d-bibliography src="{{ page.bibliography | prepend: '/assets/bibliography/' | relative_url }}"></d-bibliography>

      {% if site.disqus_shortname and page.disqus_comments %}{% include disqus.liquid %}{% endif %}
      {% if site.giscus.repo and page.giscus_comments %}
        {% include giscus.liquid %}
      {% endif %}
    </div>

    <!-- Footer -->
    {% include footer.liquid %}
    {% include scripts/bootstrap.liquid %}
    {% include scripts/analytics.liquid %}
    {% include scripts/progressBar.liquid %}
    {% include scripts/back_to_top.liquid %}
  </body>
</html>
